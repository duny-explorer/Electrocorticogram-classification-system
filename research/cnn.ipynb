{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.fft import fft, ifft\n",
    "import os\n",
    "import pyedflib\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, ws, fourier):\n",
    "        self.df = df\n",
    "        self.ws = ws\n",
    "        self.fourier = fourier\n",
    "        \n",
    "        # Извлекаем временные ряды и метки\n",
    "        self.time_series = df['emb'].values\n",
    "        self.labels = df['label'].map({'none': 0, 'swd': 1, 'is': 2, 'ds': 3}).values\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.time_series[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.050875000000000004, 0.0418125, 0.0518125000...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.0885625, -0.1311875, -0.148875, -0.12975, ...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.185375, 0.2161875, 0.1673125, 0.1468125, 0....</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.141625, -0.149, -0.1784375, -0.2235, -0.21...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.21106250000000001, 0.210875, 0.2288125, 0.2...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518359</th>\n",
       "      <td>[0.07981250000000001, 0.079125, 0.0873125, 0.0...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518360</th>\n",
       "      <td>[0.04025, 0.0349375, 0.03625, 0.01325, 0.02162...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518361</th>\n",
       "      <td>[0.07225, 0.063625, 0.0226875, 0.0071875, 0.02...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518362</th>\n",
       "      <td>[0.05375, 0.058875000000000004, 0.08325, 0.096...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518363</th>\n",
       "      <td>[0.0583125, 0.04825, 0.0345625, 0.007125, 0.02...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518343 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      emb label\n",
       "0       [0.050875000000000004, 0.0418125, 0.0518125000...  none\n",
       "1       [-0.0885625, -0.1311875, -0.148875, -0.12975, ...  none\n",
       "2       [0.185375, 0.2161875, 0.1673125, 0.1468125, 0....  none\n",
       "3       [-0.141625, -0.149, -0.1784375, -0.2235, -0.21...  none\n",
       "4       [0.21106250000000001, 0.210875, 0.2288125, 0.2...  none\n",
       "...                                                   ...   ...\n",
       "518359  [0.07981250000000001, 0.079125, 0.0873125, 0.0...  none\n",
       "518360  [0.04025, 0.0349375, 0.03625, 0.01325, 0.02162...  none\n",
       "518361  [0.07225, 0.063625, 0.0226875, 0.0071875, 0.02...  none\n",
       "518362  [0.05375, 0.058875000000000004, 0.08325, 0.096...  none\n",
       "518363  [0.0583125, 0.04825, 0.0345625, 0.007125, 0.02...  none\n",
       "\n",
       "[518343 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('data/data.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [[0.050875000000000004, 0.0418125, 0.051812500...\n",
       "1         [[-0.0885625, -0.1311875, -0.148875, -0.12975,...\n",
       "2         [[0.185375, 0.2161875, 0.1673125, 0.1468125, 0...\n",
       "3         [[-0.141625, -0.149, -0.1784375, -0.2235, -0.2...\n",
       "4         [[0.21106250000000001, 0.210875, 0.2288125, 0....\n",
       "                                ...                        \n",
       "518359    [[0.07981250000000001, 0.079125, 0.0873125, 0....\n",
       "518360    [[0.04025, 0.0349375, 0.03625, 0.01325, 0.0216...\n",
       "518361    [[0.07225, 0.063625, 0.0226875, 0.0071875, 0.0...\n",
       "518362    [[0.05375, 0.058875000000000004, 0.08325, 0.09...\n",
       "518363    [[0.0583125, 0.04825, 0.0345625, 0.007125, 0.0...\n",
       "Name: emb, Length: 518343, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emb'] = df['emb'].map(lambda x: x.reshape((3, -1)))\n",
    "df['emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.050875000000000004, 0.0418125, 0.051812500...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.0885625, -0.1311875, -0.148875, -0.12975,...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.185375, 0.2161875, 0.1673125, 0.1468125, 0...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.141625, -0.149, -0.1784375, -0.2235, -0.2...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.21106250000000001, 0.210875, 0.2288125, 0....</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518359</th>\n",
       "      <td>[[0.07981250000000001, 0.079125, 0.0873125, 0....</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518360</th>\n",
       "      <td>[[0.04025, 0.0349375, 0.03625, 0.01325, 0.0216...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518361</th>\n",
       "      <td>[[0.07225, 0.063625, 0.0226875, 0.0071875, 0.0...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518362</th>\n",
       "      <td>[[0.05375, 0.058875000000000004, 0.08325, 0.09...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518363</th>\n",
       "      <td>[[0.0583125, 0.04825, 0.0345625, 0.007125, 0.0...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518343 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      emb label\n",
       "0       [[0.050875000000000004, 0.0418125, 0.051812500...  none\n",
       "1       [[-0.0885625, -0.1311875, -0.148875, -0.12975,...  none\n",
       "2       [[0.185375, 0.2161875, 0.1673125, 0.1468125, 0...  none\n",
       "3       [[-0.141625, -0.149, -0.1784375, -0.2235, -0.2...  none\n",
       "4       [[0.21106250000000001, 0.210875, 0.2288125, 0....  none\n",
       "...                                                   ...   ...\n",
       "518359  [[0.07981250000000001, 0.079125, 0.0873125, 0....  none\n",
       "518360  [[0.04025, 0.0349375, 0.03625, 0.01325, 0.0216...  none\n",
       "518361  [[0.07225, 0.063625, 0.0226875, 0.0071875, 0.0...  none\n",
       "518362  [[0.05375, 0.058875000000000004, 0.08325, 0.09...  none\n",
       "518363  [[0.0583125, 0.04825, 0.0345625, 0.007125, 0.0...  none\n",
       "\n",
       "[518343 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['label'] != 'dds') & (df['label'] != 'sdw')]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = TimeSeriesDataset(df, ws=1000, fourier=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import random\n",
    "import traceback\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def copy_data_to_device(data, device):\n",
    "    if torch.is_tensor(data):\n",
    "        return data.to(device)\n",
    "    elif isinstance(data, (list, tuple)):\n",
    "        return [copy_data_to_device(elem, device) for elem in data]\n",
    "    raise ValueError('Недопустимый тип данных {}'.format(type(data)))\n",
    "\n",
    "\n",
    "def print_grad_stats(model):\n",
    "    mean = 0\n",
    "    std = 0\n",
    "    norm = 1e-5\n",
    "    for param in model.parameters():\n",
    "        grad = getattr(param, 'grad', None)\n",
    "        if grad is not None:\n",
    "            mean += grad.data.abs().mean()\n",
    "            std += grad.data.std()\n",
    "            norm += 1\n",
    "    mean /= norm\n",
    "    std /= norm\n",
    "    print(f'Mean grad {mean}, std {std}, n {norm}')\n",
    "\n",
    "\n",
    "def train_eval_loop(model, train_dataset, val_dataset, criterion,\n",
    "                    lr=1e-4, epoch_n=10, batch_size=32,\n",
    "                    device=None, early_stopping_patience=10, l2_reg_alpha=0,\n",
    "                    max_batches_per_epoch_train=10000,\n",
    "                    max_batches_per_epoch_val=1000,\n",
    "                    data_loader_ctor=DataLoader,\n",
    "                    optimizer_ctor=None,\n",
    "                    lr_scheduler_ctor=None,\n",
    "                    shuffle_train=True,\n",
    "                    dataloader_workers_n=0, \n",
    "                    plot=False):\n",
    "    \"\"\"\n",
    "    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n",
    "    :param model: torch.nn.Module - обучаемая модель\n",
    "    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n",
    "    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n",
    "    :param criterion: функция потерь для настройки модели\n",
    "    :param lr: скорость обучения\n",
    "    :param epoch_n: максимальное количество эпох\n",
    "    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n",
    "    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n",
    "    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n",
    "        отсутствие улучшения модели, чтобы обучение продолжалось.\n",
    "    :param l2_reg_alpha: коэффициент L2-регуляризации\n",
    "    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n",
    "    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n",
    "    :param data_loader_ctor: функция для создания объекта, преобразующего датасет в батчи\n",
    "        (по умолчанию torch.utils.data.DataLoader)\n",
    "    :return: кортеж из двух элементов:\n",
    "        - среднее значение функции потерь на валидации на лучшей эпохе\n",
    "        - лучшая модель\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "    model.to(device)\n",
    "\n",
    "    if optimizer_ctor is None:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n",
    "    else:\n",
    "        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n",
    "\n",
    "    if lr_scheduler_ctor is not None:\n",
    "        lr_scheduler = lr_scheduler_ctor(optimizer)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "\n",
    "    train_dataloader = data_loader_ctor(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n",
    "                                        num_workers=dataloader_workers_n)\n",
    "    val_dataloader = data_loader_ctor(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                      num_workers=dataloader_workers_n)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch_i = 0\n",
    "    best_model = copy.deepcopy(model)\n",
    "\n",
    "# Dynamic plot\n",
    "    if plot:\n",
    "        plot_epoch_data = []\n",
    "        plot_train_loss = []\n",
    "        plot_val_loss = []\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        line_train, = ax.plot([], [], 'r-')\n",
    "        line_val, = ax.plot([], [], 'b-')\n",
    "        ax.legend(['train', 'val'])\n",
    "        ax.set_xlim(0, epoch_n)\n",
    "\n",
    "        def add_point(epoch_i, train_loss, val_loss):\n",
    "            max_loss = max(ax.viewLim.y1 / 1.1, train_loss, val_loss)\n",
    "            ax.set_ylim(0, max_loss * 1.1)\n",
    "            \n",
    "            plot_epoch_data.append(epoch_i)\n",
    "            plot_train_loss.append(train_loss)\n",
    "            plot_val_loss.append(val_loss)\n",
    "            line_train.set_data(plot_epoch_data, plot_train_loss)\n",
    "            line_val.set_data(plot_epoch_data, plot_val_loss)\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "\n",
    "\n",
    "    for epoch_i in range(epoch_n):\n",
    "        try:\n",
    "            epoch_start = datetime.datetime.now()\n",
    "            \n",
    "\n",
    "            print('Эпоха {}'.format(epoch_i))\n",
    "\n",
    "            model.train()\n",
    "            mean_train_loss = 0\n",
    "            train_batches_n = 0\n",
    "            for batch_i, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "                if batch_i > max_batches_per_epoch_train:\n",
    "                    break\n",
    "\n",
    "                batch_x = copy_data_to_device(batch_x, device)\n",
    "                batch_y = copy_data_to_device(batch_y, device)\n",
    "\n",
    "                pred = model(batch_x)\n",
    "                loss = criterion(pred, batch_y)\n",
    "\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                mean_train_loss += float(loss)\n",
    "                train_batches_n += 1\n",
    "\n",
    "            mean_train_loss /= train_batches_n\n",
    "\n",
    "            print('Эпоха: {} итераций, {:0.2f} сек'.format(train_batches_n,\n",
    "                                                           (datetime.datetime.now() - epoch_start).total_seconds()))\n",
    "            print('Среднее значение функции потерь на обучении', mean_train_loss)\n",
    "\n",
    "\n",
    "\n",
    "            model.eval()\n",
    "            mean_val_loss = 0\n",
    "            val_batches_n = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n",
    "                    if batch_i > max_batches_per_epoch_val:\n",
    "                        break\n",
    "\n",
    "                    batch_x = copy_data_to_device(batch_x, device)\n",
    "                    batch_y = copy_data_to_device(batch_y, device)\n",
    "\n",
    "                    pred = model(batch_x)\n",
    "                    loss = criterion(pred, batch_y)\n",
    "                    print(\"batch_train\", float(loss))\n",
    "                    mean_val_loss += float(loss)\n",
    "                    val_batches_n += 1\n",
    "\n",
    "            mean_val_loss /= val_batches_n\n",
    "\n",
    "            if plot:\n",
    "                add_point(epoch_i, mean_train_loss, mean_val_loss)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            print('Среднее значение функции потерь на валидации', mean_val_loss)\n",
    "\n",
    "            if mean_val_loss < best_val_loss:\n",
    "                best_epoch_i = epoch_i\n",
    "                best_val_loss = mean_val_loss\n",
    "                best_model = copy.deepcopy(model)\n",
    "                print('Новая лучшая модель! На эпохе {}'.format(epoch_i))\n",
    "            elif epoch_i - best_epoch_i > early_stopping_patience:\n",
    "                print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(\n",
    "                    early_stopping_patience))\n",
    "                break\n",
    "\n",
    "            if lr_scheduler is not None:\n",
    "                lr_scheduler.step(mean_val_loss)\n",
    "\n",
    "            print()\n",
    "        except KeyboardInterrupt:\n",
    "            print('Досрочно остановлено пользователем')\n",
    "            break\n",
    "        except Exception as ex:\n",
    "            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n",
    "            break\n",
    "        finally:\n",
    "            if plot:\n",
    "                plt.close(fig)\n",
    "\n",
    "    return best_val_loss, best_model\n",
    "\n",
    "\n",
    "def predict_with_model(model, dataset, device=None, batch_size=32, num_workers=0, return_labels=False):\n",
    "    \"\"\"\n",
    "    :param model: torch.nn.Module - обученная модель\n",
    "    :param dataset: torch.utils.data.Dataset - данные для применения модели\n",
    "    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n",
    "    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n",
    "    :return: numpy.array размерности len(dataset) x *\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    results_by_batch = []\n",
    "\n",
    "    device = torch.device(device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        import tqdm\n",
    "        for batch_x, batch_y in tqdm.tqdm(dataloader, total=len(dataset)/batch_size):\n",
    "            batch_x = copy_data_to_device(batch_x, device)\n",
    "\n",
    "            if return_labels:\n",
    "                labels.append(batch_y.numpy())\n",
    "\n",
    "            batch_pred = model(batch_x)\n",
    "            results_by_batch.append(batch_pred.detach().cpu().numpy())\n",
    "\n",
    "    if return_labels:\n",
    "        return np.concatenate(results_by_batch, 0), np.concatenate(labels, 0)\n",
    "    else:\n",
    "        return np.concatenate(results_by_batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN1d(nn.Module):\n",
    "    def __init__(self, channels_in = 3, ws = 1000):\n",
    "        super(CNN1d, self).__init__()\n",
    "        self.act = nn.GELU()\n",
    "        self.conv11 = nn.Conv1d(in_channels=channels_in, \n",
    "                               out_channels=64,\n",
    "                               kernel_size=100,\n",
    "                               padding=1,\n",
    "                               padding_mode='circular',\n",
    "                               bias=False)\n",
    "        self.bn11 = nn.BatchNorm1d(64)\n",
    "        self.conv12 = nn.Conv1d(in_channels=64, \n",
    "                               out_channels=128,\n",
    "                               kernel_size=100,\n",
    "                               padding=1,\n",
    "                               padding_mode='circular',\n",
    "                               bias=False)\n",
    "        self.bn12 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv21 = nn.Conv1d(in_channels=128, \n",
    "                               out_channels=128,\n",
    "                               kernel_size=3,\n",
    "                               padding=1,\n",
    "                               padding_mode='zeros',\n",
    "                               bias=False)\n",
    "        self.bn21 = nn.BatchNorm1d(128)\n",
    "        self.conv22 = nn.Conv1d(in_channels=128, \n",
    "                               out_channels=128,\n",
    "                               kernel_size=3,\n",
    "                               padding=1,\n",
    "                               padding_mode='zeros',\n",
    "                               bias=False)\n",
    "        self.bn22 = nn.BatchNorm1d(128)\n",
    "        self.adaptive_pool = nn.AvgPool1d(kernel_size=100)\n",
    "        self.fc = nn.Linear(256, 4)\n",
    "\n",
    "        self.wavelets = nn.Sequential(\n",
    "            self.conv11,\n",
    "            self.act,\n",
    "            self.bn11,\n",
    "            self.conv12,\n",
    "            self.act,\n",
    "            self.bn12\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            self.conv21,\n",
    "            self.act,\n",
    "            self.pool,\n",
    "            self.bn21,\n",
    "            self.conv22,\n",
    "            self.act,\n",
    "            self.pool,\n",
    "            self.bn22,\n",
    "            self.adaptive_pool\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.type(torch.cuda.FloatTensor)\n",
    "        x = self.wavelets(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CNN1d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = df[:int(0.85 * len(df))]\n",
    "val_dataset = df[int(0.85 * len(df)):]\n",
    "\n",
    "train_dataset = TimeSeriesDataset(train_dataset, ws=1000, fourier=400)\n",
    "val_dataset = TimeSeriesDataset(val_dataset, ws=1000, fourier=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на валидации 0.5510957473172591\n",
      "Новая лучшая модель! На эпохе 19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_loss, best_model = train_eval_loop(model=model, \n",
    "                train_dataset=train_dataset, \n",
    "                val_dataset=val_dataset, \n",
    "                criterion=nn.CrossEntropyLoss(),\n",
    "                lr=1e-3, \n",
    "                epoch_n=20, \n",
    "                batch_size=3000,\n",
    "                device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\", \n",
    "                early_stopping_patience=20, \n",
    "                l2_reg_alpha=0.15,\n",
    "                max_batches_per_epoch_train=10000,\n",
    "                max_batches_per_epoch_val=1000,\n",
    "                data_loader_ctor=DataLoader,\n",
    "                optimizer_ctor=torch.optim.Adam,\n",
    "                lr_scheduler_ctor=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                shuffle_train=False,\n",
    "                dataloader_workers_n=1, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/golden/Ati4x1_15m_H2O_6h_edited.edf'\n",
    "f = pyedflib.EdfReader(file_name)\n",
    "n = f.signals_in_file\n",
    "n_a = f.annotations_in_file\n",
    "signal_labels = f.getSignalLabels()\n",
    "sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "\n",
    "for i in np.arange(n):\n",
    "    sigbufs[i, :] = f.readSignal(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 171400.,  184180., 2698120., 2705430., 2874740., 2879860.,\n",
       "        5692550., 5716010., 8002510., 8038110., 8059800., 8090150.,\n",
       "        8090190., 8098990.]),\n",
       " array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1.]),\n",
       " array(['ds1', 'ds2', 'is1', 'is2', 'is1', 'is2', 'ds1', 'ds2', 'ds1',\n",
       "        'ds2', 'ds1', 'ds2', 'is1', 'is2'], dtype='<U3')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = list(f.readAnnotations())\n",
    "annotations[0] = annotations[0] / (f.getFileDuration() / sigbufs.shape[1])\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_metric(data, ground_trouth):\n",
    "    gr = []\n",
    "    d = []\n",
    "    if 'is' in ground_trouth:\n",
    "        gr.append(np.array(ground_trouth) == 'is')\n",
    "        d.append(np.array(data) == 'is')\n",
    "        \n",
    "    \n",
    "    if 'ds' in ground_trouth:\n",
    "        gr.append(np.array(ground_trouth) == 'ds')\n",
    "        d.append(np.array(data) == 'ds')\n",
    "    \n",
    "    if 'swd' in ground_trouth:\n",
    "        gr.append(np.array(ground_trouth) == 'swd')\n",
    "        d.append(np.array(data) == 'swd')\n",
    "    \n",
    "    gr.append(np.array(ground_trouth) == 'none')\n",
    "    d.append(np.array(data) == 'none')\n",
    "    \n",
    "    result = 0\n",
    "    for i in range(len(d)):\n",
    "        result += jaccard_score(gr[i], d[i])\n",
    "    \n",
    "    return result/len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for i in tqdm(range(0, len(sigbufs[0]), 100)):\n",
    "    if i + 1000 < len(sigbufs[0]):\n",
    "        data = best_model([sigbufs[:, i: i+1000]])\n",
    "        mode = data.argmax()\n",
    "        result.append([data.argmax(), i+900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6048101,
     "sourceId": 9855638,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "hacks",
   "language": "python",
   "name": "hacks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
